{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock and Stability.ai Stable Diffusion XL 1.0 Video Animation Demo\n",
    "\n",
    "In this 3-part demonstration we will learn how to use the AWS SDK for Python (Boto3) to create Generative AI images and simple video animations using [Amazon Bedrock](https://aws.amazon.com/bedrock/) and [Stability.ai](https://stability.ai/stable-image) Stable Diffusion XL 1.0 model.\n",
    "\n",
    "1. Text-to-image\n",
    "2. Image-to-image\n",
    "3. Video-to-video (video-frame-frame-video)\n",
    "\n",
    "Technologies:\n",
    "\n",
    "- **Amazon Bedrock**: Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon via a single API\n",
    "\n",
    "- **Stable Diffusion XL Model**: Stable Diffusion XL or SDXL is the latest image generation model that is tailored towards more photorealistic outputs with more detailed imagery and composition compared to previous SD models, including SD 2.1. Stable Diffusion XL is a significant advancement in image generation capabilities, offering enhanced image composition and face generation that results in stunning visuals and realistic aesthetics.\n",
    "\n",
    "References:\n",
    "\n",
    "- [Amazon Bedrock SDXL 1.0 Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-image-image.html)\n",
    "- [Stability.ai API Documentation](https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/imageToImage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Environment\n",
    "\n",
    "Create a virtual Python environment and install the required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Create virtual python environment\n",
    "python3 -m pip install virtualenv -Uq\n",
    "virtualenv bedrock-venv\n",
    "python3 -m venv bedrock-venv\n",
    "\n",
    "source bedrock-venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Install Python requirements\n",
    "python3 -m pip install -r requirements.txt -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select New Kernel\n",
    "\n",
    "Change the kernel for this notebook to `bedrock-venv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Your AWS Credentials\n",
    "\n",
    "Your method of authentication may vary depending on your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with AWS using your credentials\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = (\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install FFmpeg\n",
    "\n",
    "Install [FFmpeg](https://ffmpeg.org/). Directions vary depending in your OS: Mac, Linux, or Windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Install ffmpeg on mac using homebrew\n",
    "# https://phoenixnap.com/kb/ffmpeg-mac\n",
    "\n",
    "brew update\n",
    "# brew upgrade # this is optional (note: will upgrade all packages and could take awhile)\n",
    "brew install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Subdirectories for Content\n",
    "\n",
    "We will use six different folders to hold our content: the source and generated images, frames, and videos. Four of the subdirectories exist in the project with samples. We will create the remaining two subdirectories. For the source and generated frames subdirectories, we will create additional subdirectories to hold each video's frames. Feel free to create additional subdirectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir ./content/source_videos/\n",
    "mkdir ./content/source_frames/\n",
    "\n",
    "mkdir ./content/source_frames/demo1/\n",
    "mkdir ./content/source_frames/demo2/\n",
    "mkdir ./content/source_frames/demo3/\n",
    "mkdir ./content/source_frames/demo4/\n",
    "\n",
    "mkdir ./content/generated_frames/demo1/\n",
    "mkdir ./content/generated_frames/demo2/\n",
    "mkdir ./content/generated_frames/demo3/\n",
    "mkdir ./content/generated_frames/demo4/\n",
    "\n",
    "ls ./content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text-to-Image Example\n",
    "\n",
    "Let's start with a simple example of text-to-image. We will use the Boto3 Python SDK with Amazon Bedrock Stability.ai Stable Diffusion XL 1.0. We will pass in a positive and negative prompt and generate an image. The code below is a modified version of the AWS Documentation's [sample code](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-text-image.html#model-parameters-diffusion-1-0-code-example).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Bedrock Model ID used throughout this notebook\n",
    "# Model IDs: https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns\n",
    "MODEL_ID = \"stability.stable-diffusion-xl-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of visual contents used throughout this notebook\n",
    "SOURCE_IMAGES = \"./content/source_images\"\n",
    "SOURCE_VIDEOS = \"./content/source_videos\"\n",
    "SOURCE_FRAMES = \"./content/source_frames\"\n",
    "\n",
    "GENERATED_IMAGES = \"./content/generated_images\"\n",
    "GENERATED_FRAMES = \"./content/generated_frames\"\n",
    "GENERATED_VIDEOS = \"./content/generated_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of AWS example code: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-text-image.html#model-parameters-diffusion-1-0-code-example\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\"\"\"\n",
    "Shows how to generate an image with SDXL 1.0 (on demand).\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class ImageError(Exception):\n",
    "    \"\"\"\n",
    "    Custom exception for errors returned by SDXL 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "# Set up logging for notebook environment\n",
    "logger = logging.getLogger(__name__)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "handler = logging.StreamHandler()\n",
    "logger.addHandler(handler)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def generate_image_from_text(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate an image using SDXL 1.0 on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        image_bytes (bytes): The image generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Generating image with SDXL model %s\", model_id)\n",
    "\n",
    "    bedrock = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    logger.info(f\"Bedrock result: {response_body['result']}\")\n",
    "\n",
    "    base64_image = response_body.get(\"artifacts\")[0].get(\"base64\")\n",
    "    base64_bytes = base64_image.encode(\"ascii\")\n",
    "    image_bytes = base64.b64decode(base64_bytes)\n",
    "\n",
    "    finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\")\n",
    "\n",
    "    if finish_reason == \"ERROR\" or finish_reason == \"CONTENT_FILTERED\":\n",
    "        raise ImageError(f\"Image generation error. Error code is {finish_reason}\")\n",
    "\n",
    "    logger.info(\"Successfully generated image with the SDXL 1.0 model %s\", model_id)\n",
    "\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def text_to_image_request(\n",
    "    model_id,\n",
    "    positive_prompt,\n",
    "    negative_prompt,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrypoint for SDXL example.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        positive_prompt (str): The positive prompt to use.\n",
    "        negative_prompt (str): The negative prompt to use.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build request body\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"text_prompts\": [\n",
    "                {\"text\": positive_prompt, \"weight\": 1},\n",
    "                {\"text\": negative_prompt, \"weight\": -1},\n",
    "            ],\n",
    "            \"height\": 1024,\n",
    "            \"width\": 1024,\n",
    "            \"cfg_scale\": 12,\n",
    "            \"clip_guidance_preset\": \"NONE\",\n",
    "            \"sampler\": \"K_DPMPP_2M\",\n",
    "            \"samples\": 1,\n",
    "            \"seed\": 123456,\n",
    "            \"steps\": 25,\n",
    "            \"style_preset\": \"fantasy-art\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Generate and save image\n",
    "    try:\n",
    "        image_bytes = generate_image_from_text(model_id=model_id, body=body)\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        epoch_time = int(time.time())\n",
    "        generated_image_path = f\"{GENERATED_IMAGES}/image_{epoch_time}.jpg\"\n",
    "        logger.info(f\"Generated image: {generated_image_path}\")\n",
    "        image.save(generated_image_path, format=\"JPEG\", quality=95)\n",
    "    except ClientError as err:\n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "    except ImageError as err:\n",
    "        logger.error(err.message)\n",
    "\n",
    "    else:\n",
    "        logger.info(f\"Finished generating image with SDXL model {model_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a 77-token limit for prompts for the SXDL 1.0 model\n",
    "\n",
    "# Phoenix prompt inspiration: https://civitai.com/images/3030250\n",
    "# preset style: fantasy-art, cfg_scale: 15, sampler: K_DPMPP_2M, samples: 1, seed: 72746264, steps: 25\n",
    "POSITIVE_PROMPT = \"mythical beast, Phoenix, big eyes, sharp beak, long flowing feathers, bright colors, outdoors, perched on branch, no_humans, fire,scenery, cinematic lighting, strong contrast, high level of detail, best quality, masterpiece, best quality, ultra-detailed, masterpiece, hires, 8k\"\n",
    "NEGATIVE_PROMPT = \"(worst quality:1.5), (low quality:1.5), (normal quality:1.5), lowres, bad anatomy, bad hands, watermark, moles, toe, bad-picture-chill-75v, realisticvision-negative-embedding, (monochrome:1.5), (grayscale:1.5), (bad proportions:1.3)\"\n",
    "\n",
    "# Samurai prompt inspiration: https://prompthero.com/prompt/accdc184a10\n",
    "# preset style: fantasy-art, cfg_scale: 15, sampler: K_DPMPP_2M, samples: 1, seed: 72746264, steps: 40\n",
    "# POSITIVE_PROMPT = \"digital wallpaper portrait of a samurai in black armor, highly detailed, at night, dramatic cinematic lighting, rainy, reflections in puddles, dramatic composition, emotionally profound, leaving an indelible and haunting impression on psyche, very intricate, by Milo Manara and Russ Mills\"\n",
    "# NEGATIVE_PROMPT = \"(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers:1.5), (mutated hands:1.5), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera, name, signature, watermark, logo, autograph, trademark, cut off, censored, bad anatomy, bad body, bad face, bad teeth, deformities, (boring, uninteresting:1.1)\"\n",
    "\n",
    "# Cat prompt inspiration: https://civitai.com/images/6826034\n",
    "# No preset style, cfg_scale: 12, sampler: K_DPMPP_2M, samples: 1, seed: 72746264, steps: 25\n",
    "# POSITIVE_PROMPT = \"amazing quality, masterpiece, best quality, hyper detailed, ultra detailed, UHD, perfect anatomy, magic world, (kitten and fish:1.4), fish in the air, spell magic to get fresh fish as food,( fish jumping from magic book:1.3), energy flow, a full body of a cute kitten, kawaii, wearing witches robe, witches hat, holding magic book, magic book on one hand, spell magic, hkmagic, extremely detailed, glowneon, glowing\"\n",
    "# NEGATIVE_PROMPT = \"FastNegativeV2, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.3), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words\"\n",
    "\n",
    "# Robot prompt inspiration: https://civitai.com/images/6935869\n",
    "# preset style: fantasy-art, cfg_scale: 15, sampler: K_DPMPP_2M, samples: 1, seed: 72746264, steps: 40\n",
    "# POSITIVE_PROMPT = \"masterpiece, best quality, cinematic film still, realistic, portrait, solo, white mecha robot, cape, science fiction, torn clothes, glowing, standing, robot joints, mecha, armor, cowboy shot, (floating cape:1.3), intense sunlight, silver dragonborn, outdoors, landscape, nature highres, 4k, 8k, intricate detail, cinematic lighting, amazing quality, wallpaper\"\n",
    "# NEGATIVE_PROMPT = \"nipples, (low quality, worst quality:1.4), cgi, text, signature, watermark, extra limbs\"\n",
    "\n",
    "# Batman prompt inspiration: https://medium.com/phygital/top-40-useful-prompts-for-stable-diffusion-xl-008c03dd0557\n",
    "# No preset style, cfg_scale: 5, sampler: K_DPMPP_2M, samples: 1, seed: 72746264, steps: 35\n",
    "# POSITIVE_PROMPT = \"batman, cute modern disney style, Pixar 3d portrait, ultra detailed, gorgeous, 3d zbrush, trending on dribbble, 8k render\"\n",
    "# NEGATIVE_PROMPT = \"\"\n",
    "\n",
    "# Dragon prompt inspiration: https://civitai.com/images/7029232\n",
    "# No negative prompt, preset style: anime, cfg_scale: 15, sampler: K_DPMPP_2M, samples: 1, seed: 1121313, steps: 25\n",
    "# POSITIVE_PROMPT = \"silk screen art, (ukiyo-e:1.1), (painted by Kim Hong-do:1.1), sharp oriental dragon, green and gold with a bit of blue, katsuhiro otomo, line art, glitch art, hergé\"\n",
    "# NEGATIVE_PROMPT = \"\"\n",
    "\n",
    "# Autumn girl prompt inspiration: https://civitai.com/images/6840704\n",
    "# v1 No negative prompt, no preset style, cfg_scale: 5, sampler: K_DPMPP_2M, samples: 1, seed: 123456, steps: 30\n",
    "# v2 No negative prompt, no preset style, cfg_scale: 15, sampler: K_DPMPP_2M, samples: 1, seed: 123456, steps: 25\n",
    "# POSITIVE_PROMPT = \"mysterious silhouette forest woman, by Minjae Lee, Carne Griffiths, Emily Kell, Geoffroy Thoorens, Aaron Horkey, Jordan Grimmer, Greg Rutkowski, amazing depth, masterwork, surreal, geometric patterns, intricately detailed, bokeh, perfect balanced, deep fine borders, artistic photorealism , smooth, great masterwork by head of prompt engineering\"\n",
    "# NEGATIVE_PROMPT = \"boring,text,signature,logo,watermark,low quality, bad quality, loose artifacts, grainy, blurry, long neck, closed eyes, face jewellery\"\n",
    "\n",
    "text_to_image_request(\n",
    "    MODEL_ID,\n",
    "    POSITIVE_PROMPT,\n",
    "    NEGATIVE_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example of a generated image\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "SOURCE_IMAGE = f\"{GENERATED_IMAGES}/text_to_image_samples/phoenix_1.jpg\"\n",
    "source_image = Image.open(SOURCE_IMAGE).resize((384, 384))\n",
    "display(source_image)\n",
    "print(SOURCE_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image-to-Image Example\n",
    "Let's start with a simple example of image-to-image using a single image. We will use the Boto3 Python SDK with Amazon Bedrock Stability.ai Stable Diffusion XL 1.0. We will pass in a positive and negative prompt along with a source image and using those, generate a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Image: African Lilac-breasted roller\n",
    "# Image source: https://unsplash.com/photos/blue-and-brown-bird-facing-sideways-aXe4Ufe3IV4\n",
    "# Source image has been cropped to 3456 × 3456 pixels and brightened\n",
    "\n",
    "SOURCE_IMAGE = f\"{SOURCE_IMAGES}/image_samples/bird_cropped.jpg\"\n",
    "source_image = Image.open(SOURCE_IMAGE).resize((384, 384))\n",
    "display(source_image)\n",
    "print(SOURCE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of AWS example code: https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion-1-0-image-image.html#model-parameters-diffusion-1-0-image-image-code-example\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\"\"\"\n",
    "Shows how to generate an image from a reference image with SDXL 1.0 (on demand).\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from enum import Enum, unique\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class ImageToImageRequest:\n",
    "    \"\"\"\n",
    "    Class for handling image to image request parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_width,\n",
    "        image_height,\n",
    "        positive_prompt,\n",
    "        negative_prompt,\n",
    "        init_image_mode=\"IMAGE_STRENGTH\",\n",
    "        image_strength=0.5,\n",
    "        cfg_scale=7,\n",
    "        clip_guidance_preset=\"SLOWER\",\n",
    "        sampler=\"K_DPMPP_2M\",\n",
    "        samples=1,\n",
    "        seed=1,\n",
    "        steps=30,\n",
    "        style_preset=\"photographic\",\n",
    "        extras=None,\n",
    "    ):\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.positive_prompt = positive_prompt\n",
    "        self.negative_prompt = negative_prompt\n",
    "        self.init_image_mode = init_image_mode\n",
    "        self.image_strength = image_strength\n",
    "        self.cfg_scale = cfg_scale\n",
    "        self.clip_guidance_preset = clip_guidance_preset\n",
    "        self.sampler = sampler\n",
    "        self.samples = samples\n",
    "        self.seed = seed\n",
    "        self.steps = steps\n",
    "        self.style_preset = style_preset\n",
    "        self.extras = extras\n",
    "\n",
    "\n",
    "@unique\n",
    "class StylesPresets(Enum):\n",
    "    \"\"\"\n",
    "    Enumerator for SDXL style presets.\n",
    "    \"\"\"\n",
    "\n",
    "    THREE_D_MODEL = \"3d-model\"\n",
    "    ANALOG_FILM = \"analog-film\"\n",
    "    ANIME = \"anime\"\n",
    "    CINEMATIC = \"cinematic\"\n",
    "    COMIC_BOOK = \"comic-book\"\n",
    "    DIGITAL_ART = \"digital-art\"\n",
    "    ENHANCE = \"enhance\"\n",
    "    FANTASY_ART = \"fantasy-art\"\n",
    "    ISOMETRIC = \"isometric\"\n",
    "    LINE_ART = \"line-art\"\n",
    "    LOW_POLY = \"low-poly\"\n",
    "    MODELING_COMPOUND = \"modeling-compound\"\n",
    "    NEON_PUNK = \"neon-punk\"\n",
    "    ORIGAMI = \"origami\"\n",
    "    PHOTOGRAPHIC = \"photographic\"\n",
    "    PIXEL_ART = \"pixel-art\"\n",
    "    TILE_TEXTURE = \"tile-texture\"\n",
    "\n",
    "\n",
    "class ImageError(Exception):\n",
    "    \"\"\"\n",
    "    Custom exception for errors returned by SDXL 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "# Set up logging for notebook environment\n",
    "logger = logging.getLogger(__name__)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "handler = logging.StreamHandler()\n",
    "logger.addHandler(handler)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def generate_image_from_image(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate an image using SDXL 1.0 on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        image_bytes (bytes): The image generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Generating image with SDXL model %s\", model_id)\n",
    "\n",
    "    bedrock = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    logger.info(f\"Bedrock result: {response_body['result']}\")\n",
    "\n",
    "    base64_image = response_body.get(\"artifacts\")[0].get(\"base64\")\n",
    "    base64_bytes = base64_image.encode(\"ascii\")\n",
    "    image_bytes = base64.b64decode(base64_bytes)\n",
    "\n",
    "    finish_reason = response_body.get(\"artifacts\")[0].get(\"finishReason\")\n",
    "\n",
    "    if finish_reason == \"ERROR\" or finish_reason == \"CONTENT_FILTERED\":\n",
    "        raise ImageError(f\"Image generation error. Error code is {finish_reason}\")\n",
    "\n",
    "    logger.info(\"Successfully generated image with the SDXL 1.0 model %s\", model_id)\n",
    "\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def image_to_image_request(\n",
    "    imageToImageRequest,\n",
    "    source_image,\n",
    "    generated_images,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrypoint for SDXL example.\n",
    "    Args:\n",
    "        imageToImageRequest (ImageToImageRequest): The image to image request to use.\n",
    "        generated_images (str): The directory to save the generated images to.\n",
    "        source_image (str): The source image to use.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read source image from file and encode as base64 strings\n",
    "    image = Image.open(source_image)\n",
    "    new_image = image.resize(\n",
    "        (imageToImageRequest.image_width, imageToImageRequest.image_height)\n",
    "    )\n",
    "    new_image.save(source_image)\n",
    "\n",
    "    with open(source_image, \"rb\") as image_file:\n",
    "        init_image = base64.b64encode(image_file.read()).decode(\"utf8\")\n",
    "\n",
    "    # Build request body\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"text_prompts\": [\n",
    "                {\"text\": imageToImageRequest.positive_prompt, \"weight\": 1},\n",
    "                {\"text\": imageToImageRequest.negative_prompt, \"weight\": -1},\n",
    "            ],\n",
    "            \"init_image\": init_image,\n",
    "            \"init_image_mode\": imageToImageRequest.init_image_mode,\n",
    "            \"image_strength\": imageToImageRequest.image_strength,\n",
    "            \"cfg_scale\": imageToImageRequest.cfg_scale,\n",
    "            \"clip_guidance_preset\": imageToImageRequest.clip_guidance_preset,\n",
    "            \"sampler\": imageToImageRequest.sampler,\n",
    "            \"samples\": imageToImageRequest.samples,\n",
    "            \"seed\": imageToImageRequest.seed,\n",
    "            \"steps\": imageToImageRequest.steps,\n",
    "            \"style_preset\": imageToImageRequest.style_preset,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Source image: {source_image}\")\n",
    "        image_bytes = generate_image_from_image(model_id=MODEL_ID, body=body)\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        epoch_time = int(time.time())\n",
    "        generated_image_path = f\"{generated_images}/image_{epoch_time}.jpg\"\n",
    "        logger.info(f\"Generated image: {generated_image_path}\")\n",
    "        # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#png\n",
    "        # image.save(generated_image_path, format=\"PNG\", compress_level=1)\n",
    "        # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#jpeg-saving\n",
    "        image.save(generated_image_path, format=\"JPEG\", quality=95)\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "    except ImageError as err:\n",
    "        logger.error(err.message)\n",
    "\n",
    "    else:\n",
    "        logger.info(f\"Finished generating image with SDXL model {MODEL_ID}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-to-image bird example\n",
    "\n",
    "# Prompt inspiration: https://civitai.com/images/3030250\n",
    "POSITIVE_PROMPT = \"mythical beast, Phoenix, big eyes, sharp beak, long flowing feathers, bright colors, outdoors, perched on branch, no_humans, fire,scenery, cinematic lighting, strong contrast, high level of detail, best quality, masterpiece, best quality, ultra-detailed, masterpiece, hires, 8k\"\n",
    "NEGATIVE_PROMPT = \"(worst quality:1.5), (low quality:1.5), (normal quality:1.5), lowres, bad anatomy, bad hands, watermark, moles, toe, bad-picture-chill-75v, realisticvision-negative-embedding, (monochrome:1.5), (grayscale:1.5), (bad proportions:1.3)\"\n",
    "\n",
    "SOURCE_IMAGE = f\"{SOURCE_IMAGES}/image_samples/bird_cropped.jpg\"\n",
    "\n",
    "# Maximum resolution for SDXL v1.0 is 1,048,576 pixels/frame (e.g., 1024 x 1024)\n",
    "# Pixel width and height of the image to generate must be a multiple of 64\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=1024,\n",
    "    image_height=1024,\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.35,\n",
    "    cfg_scale=7,\n",
    "    clip_guidance_preset=\"NONE\",\n",
    "    sampler=\"K_DPMPP_2M\",\n",
    "    samples=1,\n",
    "    seed=72746264,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.FANTASY_ART.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "image_to_image_request(\n",
    "    imageToImageRequest,\n",
    "    SOURCE_IMAGE,\n",
    "    GENERATED_IMAGES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_IMAGE = f\"{SOURCE_IMAGES}/image_samples/bird_cropped.jpg\"\n",
    "source_image = Image.open(SOURCE_IMAGE).resize((384, 384))\n",
    "display(source_image)\n",
    "print(SOURCE_IMAGE)\n",
    "print(\"\\n\")\n",
    "\n",
    "GENERATED_IMAGE = f\"{GENERATED_IMAGES}/image_to_image_samples/image_to_image_00.jpg\"\n",
    "generated_image = Image.open(GENERATED_IMAGE).resize((384, 384))\n",
    "display(generated_image)\n",
    "print()\n",
    "print(f\"file path: {GENERATED_IMAGE}\")\n",
    "print(\"image_strength: 0.4\")\n",
    "print(\"cfg_scale: 7\")\n",
    "print(\"sampler: K_EULER\")\n",
    "print(\"seed: 72746264\")\n",
    "print(\"steps: 25\")\n",
    "print(\"style_preset: fantasy-art\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Image-to-Image Variations\n",
    "\n",
    "Here a few additional image-to-image variations of the same image using different parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2i_variations = [\n",
    "    {\n",
    "        \"name\": \"image_to_image_02\",\n",
    "        \"image_strength\": 0.5,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"seed\": 72746264,\n",
    "        \"steps\": 25,\n",
    "        \"style_preset\": \"anime\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"image_to_image_03\",\n",
    "        \"image_strength\": 0.3,\n",
    "        \"cfg_scale\": 10,\n",
    "        \"seed\": 72746264,\n",
    "        \"steps\": 50,\n",
    "        \"style_preset\": \"anime\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"image_to_image_04\",\n",
    "        \"image_strength\": 0.2,\n",
    "        \"cfg_scale\": 15,\n",
    "        \"seed\": 72746264,\n",
    "        \"steps\": 50,\n",
    "        \"style_preset\": \"anime\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"image_to_image_05\",\n",
    "        \"image_strength\": 0.1,\n",
    "        \"cfg_scale\": 5,\n",
    "        \"seed\": 72746264,\n",
    "        \"steps\": 25,\n",
    "        \"style_preset\": \"digital-art\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"image_to_image_06\",\n",
    "        \"image_strength\": 0.1,\n",
    "        \"cfg_scale\": 35,\n",
    "        \"seed\": 2339845,\n",
    "        \"steps\": 50,\n",
    "        \"style_preset\": \"digital-art\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"image_to_image_07\",\n",
    "        \"image_strength\": 0.5,\n",
    "        \"cfg_scale\": 15,\n",
    "        \"seed\": 46267476,\n",
    "        \"steps\": 25,\n",
    "        \"style_preset\": \"anime\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for i in range(2, 8):\n",
    "    file_path = f\"{GENERATED_IMAGES}/image_to_image_samples/image_to_image_0{i}.png\"\n",
    "    generated_image = Image.open(file_path).resize((384, 384))\n",
    "    display(generated_image)\n",
    "    print(f\"file path: {file_path}\")\n",
    "    print(f\"image_strength: {i2i_variations[i-2]['image_strength']}\")\n",
    "    print(f\"cfg_scale: {i2i_variations[i-2]['cfg_scale']}\")\n",
    "    print(f\"seed: {i2i_variations[i-2]['seed']}\")\n",
    "    print(f\"steps: {i2i_variations[i-2]['steps']}\")\n",
    "    print(f\"style_preset: {i2i_variations[i-2]['style_preset']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generative Video-to-Video Animation Using Amazon Bedrock\n",
    "\n",
    "In this part of the demonstration will create a video animation using Amazon Bedrock Stability.ai Stable Diffusion XL 1.0 model. The high-level process is as follows:\n",
    "\n",
    "1. Select a video and copy into the `source_videos` subdirectory\n",
    "2. Split the video into individual frames (JPEG images) using [FFmpeg](https://kkroening.github.io/ffmpeg-python/)\n",
    "3. Select a contiguous series of frames that you want to animate and copy to a new directory\n",
    "4. Use the previous image-to-image method to loop through the directory of original frames and generate new frames\n",
    "5. Review the resulting generated frames for anomalies and remove any unwanted frames\n",
    "6. Recombine the generated frames into an video animation using [FFmpeg](https://kkroening.github.io/ffmpeg-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Videos\n",
    "\n",
    "For this part of the demonstration you will need an MP4 video. Since the maximum resolution for SDXL v1.0 is 1,048,576 pixels (e.g., 1024 x 1024), I recommend a video whose dimensions are 1280 x 720, which is 921,600 pixels. You can find many such copyright free videos on the Internet, including from sources such as [Pixabay](https://pixabay.com). I will be using the following video of [Red Squirrel squirrel eating](https://pixabay.com/videos/red-squirrel-squirrel-eating-food-161933/). Make sure to select the 1280×720 MP4 4.8 MB version when downloading.\n",
    "\n",
    "Copy all your source videos into the `./content/source_videos/` subdirectory within the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "# Display the source video\n",
    "# Source: https://pixabay.com/videos/red-squirrel-squirrel-eating-food-161933/\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{SOURCE_VIDEOS}/red_squirrel.mp4\",\n",
    "    width=(1280 / 2),\n",
    "    height=(720 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Video Frames\n",
    "\n",
    "Split the video into individual frames (JPEG images) using [FFmpeg](https://kkroening.github.io/ffmpeg-python/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "# Source: https://pixabay.com/videos/red-squirrel-squirrel-eating-food-161933/\n",
    "# FFmpeg arguments reference: `ffmpeg -h long`\n",
    "\n",
    "import ffmpeg\n",
    "\n",
    "SOURCE_VIDEO = f\"{SOURCE_VIDEOS}/red_squirrel.mp4\"\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo1\"\n",
    "\n",
    "(\n",
    "    ffmpeg.input(\n",
    "        SOURCE_VIDEO,\n",
    "    )\n",
    "    .output(\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame%d.jpg\",\n",
    "        start_number=1,\n",
    "        qscale=1,\n",
    "    )\n",
    "    .overwrite_output()\n",
    "    .run(quiet=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Frames from Source Frames\n",
    "\n",
    "Use the previous image-to-image technique to generate a new frame for each original frame using identical prompts and other model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "\n",
    "POSITIVE_PROMPT = \"red squirrel, in the style of Pixar animation\"\n",
    "NEGATIVE_PROMPT = \"out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
    "\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo1\"\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo1\"\n",
    "\n",
    "# Maximum resolution for SDXL v1.0 is 1,048,576 pixels/frame (e.g., 1024 x 1024)\n",
    "# Pixel width and height of the image to generate must be a multiple of 64\n",
    "# Current video frames: 1280 W x 720 H = 921,600 pixels\n",
    "# 1280/64 = 20\n",
    "# 720/64 = 11.25 > 11\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=(20 * 64),\n",
    "    image_height=(11 * 64),\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.4,\n",
    "    cfg_scale=15,\n",
    "    clip_guidance_preset=\"SLOWEST\",\n",
    "    sampler=\"K_DPMPP_2M\",  # DPM++ 2M Karras (https://stable-diffusion-art.com/samplers/)\n",
    "    samples=1,\n",
    "    seed=123234343,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.ANIME.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "# Loop through all the frames in the source video or a selection of frames\n",
    "for i in range(160, 200, 2):\n",
    "    image_to_image_request(\n",
    "        imageToImageRequest,\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg\",\n",
    "        GENERATED_VIDEO_FRAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombine Generated Frames into Video Animation\n",
    "\n",
    "Recombine the generated frames into an video animation using [FFmpeg](https://kkroening.github.io/ffmpeg-python/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "# Recombine generated frames into a video\n",
    "\n",
    "import ffmpeg\n",
    "\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo1\"\n",
    "GENERATED_VIDEO = f\"{GENERATED_VIDEOS}/demo1.mp4\"\n",
    "\n",
    "(\n",
    "    ffmpeg.input(\n",
    "        f\"{GENERATED_VIDEO_FRAMES}/*.jpg\",\n",
    "        pattern_type=\"glob\",\n",
    "        framerate=9,\n",
    "    )\n",
    "    .output(GENERATED_VIDEO)\n",
    "    .run(overwrite_output=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "# Display the generated video\n",
    "# 40 frames, 9 fps, forward only\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo1.mp4\",\n",
    "    width=1280 / 2,\n",
    "    height=720 / 2,\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Use FFmpeg from the Terminal\n",
    "\n",
    "Commands will create a 1/ normal video, 2/ reversed video, and 3/ combined video, as shown in the diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![frame_composition](./assets/video-frames.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Using the ffmpeg commands to work with video files from the terminal\n",
    "# Run the shell commands one at a time to avoid errors with I/O on slower machines\n",
    "# Creates 1/ normal video, 2/ reversed video, and 3/ combined video\n",
    "\n",
    "export GENERATED_FRAMES=\"/Users/garystafford/Documents/projects/amazon-bedrock-animation-demo/content/generated_frames\"\n",
    "export GENERATED_VIDEOS=\"/Users/garystafford/Documents/projects/amazon-bedrock-animation-demo/content/generated_videos\"\n",
    "export VIDEO_NAME=\"demo1\"\n",
    "\n",
    "ffmpeg -framerate 9 -pattern_type glob -i \"${GENERATED_FRAMES}/${VIDEO_NAME}/*.jpg\" -y \"${GENERATED_VIDEOS}/${VIDEO_NAME}.mp4\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "ffmpeg -i \"${GENERATED_VIDEOS}/${VIDEO_NAME}.mp4\" -vf reverse -y \"${GENERATED_VIDEOS}/${VIDEO_NAME}_reversed.mp4\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "echo \"file '${GENERATED_VIDEOS}/${VIDEO_NAME}.mp4'\\nfile '${GENERATED_VIDEOS}/${VIDEO_NAME}_reversed.mp4'\" > \"./vidlist.txt\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "ffmpeg -f concat -safe 0 -i \"./vidlist.txt\" -c copy -y \"${GENERATED_VIDEOS}/${VIDEO_NAME}_combined.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Video 1: Red Squirrel\n",
    "# Display the combined video\n",
    "# 40 frames, 9 fps, both forward and reverse\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo1_combined.mp4\",\n",
    "    width=(1280 / 2),\n",
    "    height=(720 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 2: Man Dancing\n",
    "# Source: https://mixkit.co/free-stock-video/cheerful-man-in-a-suit-dancing-energetically-on-a-white-45471/\n",
    "\n",
    "POSITIVE_PROMPT = \"anime-style male dancer, caucasian, brightly colored hair, dressed in bright vibrant colors clothing, 1man, white background, empty hands\"\n",
    "NEGATIVE_PROMPT = \"photographic, photorealistic, photograph, (holding objects), (objects in hands), hat, (spot light), out of frame, lowres, text, error, cropped, (background objects), scenery, spot light, worst quality, low quality, jpeg artifacts, bad eyes, bad teeth, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
    "\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo2\"\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo2\"\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=(20 * 64),\n",
    "    image_height=(11 * 64),\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.3,\n",
    "    cfg_scale=15,\n",
    "    clip_guidance_preset=\"SLOWEST\",\n",
    "    sampler=\"K_DPMPP_2M\",\n",
    "    samples=1,\n",
    "    seed=74828924,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.ANIME.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "# Loop through all the frames in the source video or a selection of frames\n",
    "for i in range(0, 100, 1):\n",
    "    image_to_image_request(\n",
    "        imageToImageRequest,\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg\",\n",
    "        GENERATED_VIDEO_FRAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 2: Man Dancing\n",
    "# Display the generated video\n",
    "# 92 frames, 9 fps, forward and reverse\n",
    "# Some retouching in Adobe Photoshop to remove strong background spot light effects\n",
    "# Deleted any frames where the dancer was holding an object\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo2_combined.mp4\",\n",
    "    width=(1280 / 2),\n",
    "    height=(704 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 3: Happy Guy\n",
    "# Source: https://www.pexels.com/video/a-happy-man-looking-at-camera-8628513/\n",
    "\n",
    "# Prompt inspiration: https://prompthero.com/prompt/15632093a39\n",
    "POSITIVE_PROMPT = \"young man with light brown wavy hair, eye glasses, looking directly at the camera, empty hands, pixar style, disney pixar, office background, ultra detailed, 1man\"\n",
    "NEGATIVE_PROMPT = \"out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, bad eyes, bad teeth, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
    "\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo3\"\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo3\"\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=(11 * 64),\n",
    "    image_height=(20 * 64),\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.5,\n",
    "    cfg_scale=10,\n",
    "    clip_guidance_preset=\"SLOWEST\",\n",
    "    sampler=\"K_DPMPP_2M\",\n",
    "    samples=1,\n",
    "    seed=74828924,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.DIGITAL_ART.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "# Loop through all the frames in the source video or a selection of frames\n",
    "for i in range(65, 114, 1):\n",
    "    image_to_image_request(\n",
    "        imageToImageRequest,\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg\",\n",
    "        GENERATED_VIDEO_FRAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 3: Happy Guy\n",
    "# Display the generated video\n",
    "# 47 frames, 9 fps, both forward and reverse\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo3_combined.mp4\",\n",
    "    width=(704 / 2),\n",
    "    height=(1280 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 4: Selfie 1\n",
    "# Prompt inspiration: https://medium.com/phygital/top-40-useful-prompts-for-stable-diffusion-xl-008c03dd0557\n",
    "\n",
    "# v1: 0.3 7 30 digital-art\n",
    "# POSITIVE_PROMPT = \"dignified older man with weather-worn features, deep wrinkles, thick graying mustache, Sam Elliot mustache, bright blue eyes, (solid black shirt:2.0), plain black t-shirt, digitally enhanced, high contrast, intimate, close-up, detailed, steady gaze, rendered in sepia tones, timeless, expressive, highly detailed, sharp focus, high resolution\"\n",
    "# NEGATIVE_PROMPT = \"beard, hair on chin, out of frame, print shirt, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, bad eyes, bad teeth, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, long neck, username, ((watermark)), ((signature)), ((text)), ((logo)), ((branding)), ((copyright)), ((trademark))\"\n",
    "\n",
    "# v2: 0.7 10 25 fantasy-art 89435389\n",
    "POSITIVE_PROMPT = \"dignified young man with wavy dark brown hair, bright blue eyes, solid black t-shirt, digitally enhanced, high contrast, intimate, close-up, detailed, steady gaze, rendered in sepia tones, timeless, expressive, highly detailed, sharp focus, high resolution\"\n",
    "NEGATIVE_PROMPT = \"beard, hair on chin, out of frame, print shirt, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, bad eyes, bad teeth, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, long neck, username, ((watermark)), ((signature)), ((text)), ((logo)), ((branding)), ((copyright)), ((trademark))\"\n",
    "\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo4\"\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo54\"\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=(9 * 64),\n",
    "    image_height=(16 * 64),\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.7,\n",
    "    cfg_scale=10,\n",
    "    clip_guidance_preset=\"SLOWEST\",\n",
    "    sampler=\"K_DPMPP_2M\",\n",
    "    samples=1,\n",
    "    seed=89435389,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.FANTASY_ART.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "# Loop through all the frames in the source video or a selection of frames\n",
    "for i in range(76, 150, 1):\n",
    "    image_to_image_request(\n",
    "        imageToImageRequest,\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg\",\n",
    "        GENERATED_VIDEO_FRAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 4: Selfie 1 v1\n",
    "# Display the generated video\n",
    "# 26 frames, 9 fps, both forward and reverse\n",
    "# Some retouching in Adobe Photoshop to remove fake artists signatures\n",
    "# Deleted any frames where the shirt had a pattern or face changed to much\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo4a_combined.mp4\",\n",
    "    width=(576 / 2),\n",
    "    height=(1024 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 4: Selfie 1 v2\n",
    "# Display the generated video\n",
    "# 24 frames, 9 fps, both forward and reverse\n",
    "# Deleted any frames where the shirt had a pattern or face changed to much\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo4b_combined.mp4\",\n",
    "    width=(576 / 2),\n",
    "    height=(1024 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 5: Selfie 2\n",
    "\n",
    "# Prompt inspiration: https://medium.com/phygital/top-40-useful-prompts-for-stable-diffusion-xl-008c03dd0557\n",
    "POSITIVE_PROMPT = \"dignified older man with weather-worn features, deep wrinkles, thick graying mustache, Sam Elliot mustache, bright blue eyes, (solid black shirt:2.0), plain black t-shirt, Newsboy Hat, Cabbie Hat, Gatsby Hat, digitally enhanced, high contrast, intimate, close-up, detailed, steady gaze, rendered in sepia tones, timeless, expressive, highly detailed, sharp focus, high resolution\"\n",
    "NEGATIVE_PROMPT = \"eyeglasses, glasses, beard, hair on chin, out of frame, print shirt, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, bad eyes, bad teeth, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, long neck, username, ((watermark)), ((signature)), ((text)), ((logo)), ((branding)), ((copyright)), ((trademark))\"\n",
    "\n",
    "SOURCE_VIDEO_FRAMES = f\"{SOURCE_FRAMES}/demo5\"\n",
    "GENERATED_VIDEO_FRAMES = f\"{GENERATED_FRAMES}/demo5\"\n",
    "\n",
    "# 7a 0.5 10 30 digital-art\n",
    "# 7b 0.2 10 25 modeling-compound 939393\n",
    "# 7a 0.9 5 50 modeling-compound 939393\n",
    "\n",
    "imageToImageRequest = ImageToImageRequest(\n",
    "    image_width=(9 * 64),\n",
    "    image_height=(16 * 64),\n",
    "    positive_prompt=POSITIVE_PROMPT,\n",
    "    negative_prompt=NEGATIVE_PROMPT,\n",
    "    init_image_mode=\"IMAGE_STRENGTH\",\n",
    "    image_strength=0.2,\n",
    "    cfg_scale=10,\n",
    "    clip_guidance_preset=\"SLOWEST\",\n",
    "    sampler=\"K_DPMPP_2M\",\n",
    "    samples=1,\n",
    "    seed=748278427,\n",
    "    steps=25,\n",
    "    style_preset=StylesPresets.MODELING_COMPOUND.value,\n",
    "    extras=None,\n",
    ")\n",
    "\n",
    "# Loop through all the frames in the source video or a selection of frames\n",
    "for i in range(200, 230, 1):\n",
    "    image_to_image_request(\n",
    "        imageToImageRequest,\n",
    "        f\"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg\",\n",
    "        GENERATED_VIDEO_FRAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 5: Selfie 2\n",
    "# Display the generated video\n",
    "# 29 frames, 6 fps, both forward and reverse\n",
    "# Deleted any frames where the eyes were bad or overall image style was dissimilar\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    url=f\"{GENERATED_VIDEOS}/demo5_combined.mp4\",\n",
    "    width=(576 / 2),\n",
    "    height=(1024 / 2),\n",
    "    html_attributes=\"controls muted autoplay loop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-Art Generative AI Animation\n",
    "\n",
    "This demonstration was very basic. If you are interested in state-of-the-art Generative AI image and video generation techniques, I would suggest looking at a combination of the AnimateDiff, ControlNet, IP-Adapter, and A1111 or ComfyUI, along with the use of custom fine-tuned SDXL models. Most high-quality animations are created with multiple fine-tuned SDXL LoRAs (Low-Rank Adaptation of Large Language Models). These tools can all be used on AWS using a GPU-based [Amazon WorkSpaces](https://aws.amazon.com/pm/workspaces/) environment.\n",
    "\n",
    "- [Automatic1111 (aka A1111) Stable Diffusion web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n",
    "- [ComfyUI Stable Diffusion web UI](https://github.com/comfyanonymous/ComfyUI)\n",
    "- [AnimateDiff](https://animatediff.github.io/)\n",
    "- [ControlNet](https://github.com/lllyasviel/ControlNet)\n",
    "- [IP-Adapter](https://github.com/tencent-ailab/IP-Adapter/)\n",
    "- [AnimateDiff for Stable Diffusion WebU (A1111)](https://github.com/continue-revolution/sd-webui-animatediff)\n",
    "- [ControlNet for Stable Diffusion WebUI (A1111)](https://github.com/Mikubill/sd-webui-controlnet)\n",
    "- [Fine-tuned Stable Diffusion XL LoRAs](https://civitai.com/models)\n",
    "- [Hugging Face: LoRA the Explorer](https://huggingface.co/spaces/multimodalart/LoraTheExplorer)\n",
    "\n",
    "If you are looking for examples of state-of-the-art Generative AI-based animations, check out [Civitai](https://civitai.com/videos). __WARNING! EXTREMELY INAPPROPRIATE CONTENT!__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
